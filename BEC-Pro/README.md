# BEC-Pro

Source: [Unmasking Contextual Stereotypes: Measuring and Mitigating BERTâ€™s Gender Bias](https://aclanthology.org/2020.gebnlp-1.1)
>Marion Bartl, Malvina Nissim, and Albert Gatt

Source dataset and documentation: https://github.com/marionbartl/gender-bias-BERT

```
@inproceedings{bartl-etal-2020-unmasking,
    title = "Unmasking Contextual Stereotypes: Measuring and Mitigating {BERT}{'}s Gender Bias",
    author = "Bartl, Marion  and
      Nissim, Malvina  and
      Gatt, Albert",
    booktitle = "Proceedings of the Second Workshop on Gender Bias in Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.gebnlp-1.1",
    pages = "1--16"
}

```

## About

Bias Evaluation Corpus with Professions (BEC-Pro) measures gender biases with respect to occupations, with 5,400 sentences constructed from templates containing a person word and one of 60 profession terms. For evaluation, person and profession words are masked.

## Data

This contains all BEC-Pro instances in English and German and the templates and vocabulary from which instances were generated.